# Lewis Koplon
# ECE 523 Engineering Applications of Machine Learning and Data Analytics
# Professor Ditzler
# Linear and Quadratic Classifiers
import math

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.lines import Line2D

def sample(probability_distribution, number_of_samples):
    # we must do n number of samples
    random_values = [0]*len(probability_distribution) # we create an array to keep track of the random numbers generated by prob distribution
    for i in range(number_of_samples):
        print("################################")
        print("Sample Number:", i)
        increment_index = find_index_of_rand_number(probability_distribution)
        random_values[increment_index] += 1
        print(random_values)


def find_index_of_rand_number(probability_distribution):
    # numpy's random number generator to generate a random number from 0 to 1
    random_number = np.random.rand() # will generate a number from 0 to 1
    print("Random Number generated:", random_number)
    for i in range(1, len(probability_distribution)): # will go through the list slicing for summing
        print("Iteration i = ", i) # the iteration we are on
        print("Array looks like:", probability_distribution[:i]) # how the array looks
        print(random_number, "<=", sum(probability_distribution[:i])) # checking if the idea of comparing the generated number to the distributions cdf is working
        if random_number <= sum(probability_distribution[:i]): # stop when the cdf is larger than rand num
            print(i-1)
            return i - 1 # slicing we must account for the addition of a one so subtract
        if i == len(probability_distribution) - 1:
            return len(probability_distribution) - 1


def test_case_1():
    p = [.3, .5, .2]
    number_of_samples = 10
    sample(p, number_of_samples)


def test_case_2():
    p = [.1, .1, .1, .3, .2, .2]
    number_of_samples = 1
    sample(p, number_of_samples)

test_case_1()